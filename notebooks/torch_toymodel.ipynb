{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"torch\" # you can also use tensorflow or torch\n",
    "\n",
    "#import keras_cv\n",
    "#import keras\n",
    "#from keras import ops\n",
    "#import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "\n",
    "#print(\"TensorFlow:\", tf.__version__)\n",
    "# print(\"Keras:\", keras.__version__)\n",
    "# print(\"KerasCV:\", keras_cv.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Config</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    verbose = 1  # Verbosity\n",
    "    seed = 42  # Random seed\n",
    "    # preset = \"mobilenet_v3_large_imagenet\"  # Name of pretrained classifier\n",
    "    image_size = [224, 224]  # Input image size\n",
    "    epochs = 1 # 12 # Training epochs\n",
    "    batch_size = 32 # 96  # Batch size\n",
    "    lr_mode = \"step\" # LR scheduler mode from one of \"cos\", \"step\", \"exp\"\n",
    "    drop_remainder = True  # Drop incomplete batches\n",
    "    num_classes = 6 # Number of classes in the dataset\n",
    "    num_folds = 5 # Number of folds to split the dataset\n",
    "    fold = 0 # Which fold to set as validation data\n",
    "    class_names = ['X4_mean', 'X11_mean', 'X18_mean',\n",
    "                   'X26_mean', 'X50_mean', 'X3112_mean',]\n",
    "    aux_class_names = list(map(lambda x: x.replace(\"mean\",\"sd\"), class_names))\n",
    "    num_classes = len(class_names)\n",
    "    aux_num_classes = len(aux_class_names)\n",
    "\n",
    "BASE_PATH = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load and process data set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Train + Valid\n",
    "df = pd.read_csv(f'{BASE_PATH}/train.csv')\n",
    "df['image_path'] = f'{BASE_PATH}/train_images/'+df['id'].astype(str)+'.jpeg'\n",
    "df.loc[:, CFG.aux_class_names] = df.loc[:, CFG.aux_class_names].fillna(-1)\n",
    "df = df[:500] # TODO temp, remove later\n",
    "display(df.head(2))\n",
    "\n",
    "# Test\n",
    "test_df = pd.read_csv(f'{BASE_PATH}/test.csv')\n",
    "test_df['image_path'] = f'{BASE_PATH}/test_images/'+test_df['id'].astype(str)+'.jpeg'\n",
    "FEATURE_COLS = test_df.columns[1:-1].tolist()\n",
    "display(test_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "\n",
    "\n",
    "def build_augmenter():\n",
    "\n",
    "    # Define augmentations\n",
    "    aug_layers = nn.ModuleList([\n",
    "        transforms.ColorJitter(brightness=0.1),\n",
    "        transforms.ColorJitter(contrast=0.1),\n",
    "        transforms.ColorJitter(saturation=(0.45, 0.55)),\n",
    "        transforms.ColorJitter(hue=0.1),\n",
    "        transforms.RandomErasing(scale=(0.06, 0.15)),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomResizedCrop(size=(CFG.image_size[0], CFG.image_size[1]), scale=(0.05, 0.15)),\n",
    "        transforms.RandomRotation(degrees=(0.6, 3.0)), # approx multiplied by 360/2pi since keras works in radians while this works in degrees\n",
    "    ])\n",
    "    \n",
    "    # Build augmenter, randomly applying augmentations\n",
    "    augmenter = transforms.RandomApply(aug_layers, p=0.5)\n",
    "                  \n",
    "    # Apply augmentations\n",
    "    def augment(inp, label):\n",
    "        aug_data = {\"images\": augmenter(inp[\"images\"])}\n",
    "        inp[\"images\"] = aug_data[\"images\"]\n",
    "        return inp, label\n",
    "    return augment\n",
    "\n",
    "\n",
    "def build_decoder(with_labels=True, target_size=CFG.image_size):\n",
    "    def decode_image(inp):\n",
    "        path = inp[\"images\"]\n",
    "        \n",
    "        # Read jpeg image\n",
    "        image = Image.open(path)\n",
    "\n",
    "        # Resize and convert to tensor\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(target_size),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        image = transform(image)\n",
    "        \n",
    "        # Rescale image\n",
    "        image = image.float()\n",
    "        image /= 255.0\n",
    "        \n",
    "        inp[\"images\"] = image\n",
    "        return inp\n",
    "\n",
    "    def decode_label(label, num_classes):\n",
    "        label = torch.tensor(label).float()\n",
    "        label = label.view(num_classes)\n",
    "        return label\n",
    "\n",
    "    def decode_with_labels(inp, labels=None):\n",
    "        inp = decode_image(inp)\n",
    "        label = decode_label(labels[0], CFG.num_classes)\n",
    "        aux_label = decode_label(labels[1], CFG.aux_num_classes)\n",
    "        return (inp, (label, aux_label))\n",
    "\n",
    "    return decode_with_labels if with_labels else decode_image\n",
    "\n",
    "class INetDataset(Dataset):\n",
    "    def __init__(self, paths, features, labels=None, aux_labels=None, decode_fn=None, augment_fn=None, augment=False):\n",
    "        self.paths = paths\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.aux_labels = aux_labels\n",
    "        self.decode_fn = decode_fn\n",
    "        self.augment_fn = augment_fn\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp = {\"images\": self.paths[idx], \"features\": self.features[idx]}\n",
    "        if self.labels is not None:\n",
    "            slices = self.decode_fn(inp, (self.labels[idx], self.aux_labels[idx]))\n",
    "            if self.augment:\n",
    "                slices = self.augment_fn(inp, (self.labels[idx], self.aux_labels[idx]))\n",
    "        else:\n",
    "            slices = self.decode_fn(inp)\n",
    "            if self.augment:\n",
    "                slices = self.augment_fn(inp)\n",
    "\n",
    "        return slices\n",
    "\n",
    "def build_dataset(\n",
    "    paths,\n",
    "    features,\n",
    "    labels=None,\n",
    "    aux_labels=None,\n",
    "    batch_size=32,\n",
    "    cache=True,\n",
    "    decode_fn=None,\n",
    "    augment_fn=None,\n",
    "    augment=False,\n",
    "    repeat=True,\n",
    "    shuffle=1024,\n",
    "    cache_dir=\"\",\n",
    "    drop_remainder=False,\n",
    "):\n",
    "    if cache_dir != \"\" and cache is True:\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "    if decode_fn is None:\n",
    "        decode_fn = build_decoder(labels is not None or aux_labels is not None)\n",
    "\n",
    "    if augment_fn is None:\n",
    "        augment_fn = build_augmenter()\n",
    "\n",
    "    dataset = INetDataset(paths, features, labels, aux_labels, decode_fn, augment_fn, augment)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=bool(shuffle), drop_last=drop_remainder, num_workers=0)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=CFG.num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Create separate bin for each traits\n",
    "for i, trait in enumerate(CFG.class_names):\n",
    "\n",
    "    # Determine the bin edges dynamically based on the distribution of traits\n",
    "    bin_edges = np.percentile(df[trait], np.linspace(0, 100, CFG.num_folds + 1))\n",
    "    df[f\"bin_{i}\"] = np.digitize(df[trait], bin_edges)\n",
    "\n",
    "# Concatenate the bins into a final bin\n",
    "df[\"final_bin\"] = (\n",
    "    df[[f\"bin_{i}\" for i in range(len(CFG.class_names))]]\n",
    "    .astype(str)\n",
    "    .agg(\"\".join, axis=1)\n",
    ")\n",
    "\n",
    "# Perform the stratified split using final bin\n",
    "df = df.reset_index(drop=True)\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(df, df[\"final_bin\"])):\n",
    "    df.loc[valid_idx, \"fold\"] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from full data\n",
    "sample_df = df.copy()\n",
    "train_df = sample_df[sample_df.fold != CFG.fold]\n",
    "valid_df = sample_df[sample_df.fold == CFG.fold]\n",
    "print(f\"# Num Train: {len(train_df)} | Num Valid: {len(valid_df)}\")\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_df[FEATURE_COLS].values)\n",
    "valid_features = scaler.transform(valid_df[FEATURE_COLS].values)\n",
    "\n",
    "# Train\n",
    "train_paths = train_df.image_path.values\n",
    "train_labels = train_df[CFG.class_names].values\n",
    "train_aux_labels = train_df[CFG.aux_class_names].values\n",
    "train_ds = build_dataset(train_paths, train_features, train_labels, train_aux_labels,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         repeat=True, shuffle=True, augment=True, cache=False)\n",
    "\n",
    "# Valid\n",
    "valid_paths = valid_df.image_path.values\n",
    "valid_labels = valid_df[CFG.class_names].values\n",
    "valid_aux_labels = valid_df[CFG.aux_class_names].values\n",
    "valid_ds = build_dataset(valid_paths, valid_features, valid_labels, valid_aux_labels,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         repeat=False, shuffle=False, augment=False, cache=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inps, tars = next(iter(train_ds))\n",
    "\n",
    "imgs = inps[\"images\"]\n",
    "num_imgs, num_cols = 8, 4\n",
    "\n",
    "plt.figure(figsize=(4 * num_cols, num_imgs // num_cols * 5))\n",
    "for i, (img, tar) in enumerate(zip(imgs[:num_imgs], tars[0][:num_imgs])):\n",
    "    plt.subplot(num_imgs // num_cols, num_cols, i + 1)\n",
    "\n",
    "    img = img.permute(1, 2, 0)  # Change (C, H, W) to (H, W, C)\n",
    "    \n",
    "    img = img.numpy()\n",
    "    tar = tar.numpy()\n",
    "    \n",
    "    img = (img - img.min()) / (img.max() + 1e-4)\n",
    "\n",
    "    formatted_tar = \"\\n\".join(\n",
    "        [\n",
    "            \", \".join(\n",
    "                f\"{name.replace('_mean','')}: {val:.2f}\"\n",
    "                for name, val in zip(CFG.class_names[j : j + 3], tar[j : j + 3])\n",
    "            )\n",
    "            for j in range(0, len(CFG.class_names), 3)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"[{formatted_tar}]\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Define loss</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "class R2Loss(torch.nn.Module):\n",
    "    def __init__(self, use_mask=False):\n",
    "        super().__init__()\n",
    "        self.use_mask = use_mask\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        if self.use_mask:\n",
    "            mask = (y_true != -1)\n",
    "            y_true = torch.where(mask, y_true, torch.zeros_like(y_true))\n",
    "            y_pred = torch.where(mask, y_pred, torch.zeros_like(y_pred))\n",
    "        SS_res = torch.sum((y_true - y_pred) ** 2, dim=0)\n",
    "        SS_tot = torch.sum((y_true - y_true.mean(dim=0)) ** 2, dim=0)\n",
    "        r2_loss = SS_res / (SS_tot + 1e-6)\n",
    "        return r2_loss.mean()\n",
    "\n",
    "class R2Metric(torchmetrics.Metric):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add_state(\"SS_res\", default=torch.zeros(6), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"SS_tot\", default=torch.zeros(6), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"num_samples\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, y_true, y_pred):\n",
    "        SS_res = torch.sum((y_true - y_pred) ** 2, dim=0)\n",
    "        SS_tot = torch.sum((y_true - y_true.mean(dim=0)) ** 2, dim=0)\n",
    "        self.SS_res.add_(SS_res)\n",
    "        self.SS_tot.add_(SS_tot)\n",
    "        self.num_samples.add_(y_true.shape[0])\n",
    "\n",
    "    def compute(self):\n",
    "        r2 = 1 - self.SS_res / (self.SS_tot + 1e-6)\n",
    "        return r2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Construct model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
    "\n",
    "class INet(nn.Module):\n",
    "    def __init__(self, feature_cols, num_classes, aux_num_classes):\n",
    "        super(INet, self).__init__()\n",
    "        self.backbone = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(1000, num_classes)\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(len(feature_cols), 326),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(326, 64),\n",
    "            nn.SELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, aux_num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, images, features):\n",
    "        x1 = self.backbone(images)\n",
    "        x1 = self.dropout1(x1)\n",
    "        x1 = self.fc1(x1)\n",
    "\n",
    "        features = features.to(torch.float32)\n",
    "        x2 = self.dense(features)\n",
    "\n",
    "        return {\"head\": x1, \"aux_head\": x2}\n",
    "\n",
    "model = INet(FEATURE_COLS, CFG.num_classes, CFG.aux_num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>LR Scheduler</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define learning rate scheduler\n",
    "import torch.optim as optim\n",
    "import math\n",
    "\n",
    "def get_lr_scheduler(optimizer, batch_size=8, mode='cos', epochs=10):\n",
    "    lr_start, lr_max, lr_min = 5e-5, 8e-6 * batch_size, 1e-5\n",
    "    lr_ramp_ep, lr_sus_ep, lr_decay = 3, 0, 0.75\n",
    "\n",
    "    def lrfn(epoch):  # Learning rate update function\n",
    "        if epoch < lr_ramp_ep: \n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep: \n",
    "            lr = lr_max\n",
    "        elif mode == 'exp': \n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        elif mode == 'step': \n",
    "            lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n",
    "        elif mode == 'cos':\n",
    "            decay_total_epochs = epochs - lr_ramp_ep - lr_sus_ep + 3\n",
    "            decay_epoch_index = epoch - lr_ramp_ep - lr_sus_ep\n",
    "            phase = math.pi * decay_epoch_index / decay_total_epochs\n",
    "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n",
    "        return lr\n",
    "\n",
    "    return optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lrfn)\n",
    "\n",
    "# Usage:\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = get_lr_scheduler(optimizer, batch_size=CFG.batch_size, mode=CFG.lr_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "# Initialize best R2 and best epoch\n",
    "best_R2 = -np.inf\n",
    "best_epoch = -1\n",
    "\n",
    "# Initialize loss functions\n",
    "loss_fn_head = R2Loss()\n",
    "loss_fn_aux_head = R2Loss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(CFG.epochs):\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "            model.train()\n",
    "            for inp, (out_features, labels) in tqdm(train_ds):\n",
    "                images = inp[\"images\"]\n",
    "                features = inp[\"features\"]\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images, features)\n",
    "\n",
    "                loss_head = loss_fn_head(outputs[\"head\"], labels)\n",
    "                loss_aux_head = loss_fn_aux_head(outputs[\"aux_head\"], labels)\n",
    "                loss = loss_head\n",
    "                loss += 0.3 * loss_aux_head\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Update learning rate\n",
    "            scheduler.step()\n",
    "    # Print profiler results\n",
    "    print(prof.key_averages().table(sort_by=\"cuda_time_total\"))\n",
    "\n",
    "    # Calculate R2 score on validation set\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        outputs = [model(inp[\"images\"], inp[\"features\"]) for inp, _ in valid_ds]\n",
    "        preds = torch.cat([o[\"head\"] for o in outputs])\n",
    "        labels = torch.cat([labels[1] for _, labels in valid_ds])\n",
    "        R2 = R2Metric()(preds, labels)\n",
    "\n",
    "    # Update best R2 and best epoch\n",
    "    if R2 > best_R2:\n",
    "        best_R2 = R2\n",
    "        best_epoch = epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Result\n",
    "print(\"#\" * 10 + \" Result \" + \"#\" * 10)\n",
    "print(f\"Best R2: {best_R2:.5f}\")\n",
    "print(f\"Best Epoch: {best_epoch}\")\n",
    "print(\"#\" * 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test_paths = test_df.image_path.values\n",
    "test_features = scaler.transform(test_df[FEATURE_COLS].values)\n",
    "test_ds = build_dataset(test_paths, test_features, batch_size=CFG.batch_size,\n",
    "                         repeat=False, shuffle=False, augment=False, cache=False)\n",
    "\n",
    "preds = []\n",
    "for inp in tqdm(test_ds):\n",
    "    with torch.no_grad():  # Disable gradient calculation to save memory\n",
    "        batch_preds = model(inp[\"images\"], inp[\"features\"])[\"head\"]\n",
    "        preds.append(batch_preds)\n",
    "\n",
    "# Concatenate all predictions\n",
    "preds = torch.cat(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = test_df[[\"id\"]].copy()\n",
    "target_cols = [x.replace(\"_mean\",\"\") for x in CFG.class_names]\n",
    "pred_df[target_cols] = preds.tolist()\n",
    "\n",
    "pred_df.to_csv(\"submission.csv\", index=False)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
