{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "import math\n",
    "\n",
    "# Torch-related\n",
    "import torch\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "import timm\n",
    "\n",
    "# General third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Config</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # General\n",
    "    seed = 42\n",
    "\n",
    "    # Data\n",
    "    base_path = \"../data\"\n",
    "    image_size = [224, 224]\n",
    "    class_names = ['X4_mean', 'X11_mean', 'X18_mean',\n",
    "                   'X26_mean', 'X50_mean', 'X3112_mean',]\n",
    "    num_classes = len(class_names)\n",
    "    aux_class_names = ['X4_sd', 'X11_sd', 'X18_sd',\n",
    "                       'X26_sd', 'X50_sd', 'X3112_sd',]\n",
    "    num_aux_classes = len(aux_class_names)\n",
    "    feature_names = None\n",
    "    num_features = 0\n",
    "    \n",
    "    # K-Fold\n",
    "    num_folds = 5\n",
    "    fold = 0\n",
    "\n",
    "    # Model\n",
    "    epochs = 1 # 12\n",
    "    batch_size = 32 # 96\n",
    "    lr_mode = \"step\"\n",
    "    profile = False\n",
    "    inet_output_size = 1408\n",
    "\n",
    "    # Loss\n",
    "    y_median = None\n",
    "    eps = None\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load and process data set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train + Valid\n",
    "df = pd.read_csv(f'{CFG.base_path}/train.csv')\n",
    "df['image_path'] = f'{CFG.base_path}/train_images/'+df['id'].astype(str)+'.jpeg'\n",
    "df.loc[:, CFG.aux_class_names] = df.loc[:, CFG.aux_class_names].fillna(-1)\n",
    "display(df.head(2))\n",
    "\n",
    "# Test\n",
    "test_df = pd.read_csv(f'{CFG.base_path}/test.csv')\n",
    "test_df['image_path'] = f'{CFG.base_path}/test_images/'+test_df['id'].astype(str)+'.jpeg'\n",
    "display(test_df.head(2))\n",
    "\n",
    "CFG.feature_names = test_df.columns[1:-1].tolist()\n",
    "CFG.num_features = len(CFG.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_augmenter():\n",
    "    # Define augmentations\n",
    "    aug_layers = torch.nn.ModuleList([\n",
    "        torchvision.transforms.ColorJitter(brightness=0.1),\n",
    "        torchvision.transforms.ColorJitter(contrast=0.1),\n",
    "        torchvision.transforms.ColorJitter(saturation=(0.45, 0.55)),\n",
    "        torchvision.transforms.ColorJitter(hue=0.1),\n",
    "        torchvision.transforms.RandomErasing(scale=(0.06, 0.15)),\n",
    "        torchvision.transforms.RandomVerticalFlip(),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.RandomResizedCrop(size=(CFG.image_size[0], CFG.image_size[1]), scale=(0.05, 0.15)),\n",
    "        torchvision.transforms.RandomRotation(degrees=(0.6, 3.0)), # Approx multiplied by 360/2pi since keras works in radians while this works in degrees\n",
    "    ])\n",
    "    \n",
    "    # Build augmenter, randomly applying augmentations\n",
    "    augmenter = torchvision.transforms.RandomApply(aug_layers, p=0.5)\n",
    "                  \n",
    "    # Apply augmentations\n",
    "    def augment(inp, label=None):\n",
    "        inp[\"images\"] = augmenter(inp[\"images\"])\n",
    "        return inp, label\n",
    "    return augment\n",
    "\n",
    "\n",
    "def build_decoder(with_labels=True):\n",
    "    def decode_image(inp):\n",
    "        # Read jpeg image\n",
    "        path = inp[\"images\"]\n",
    "        image = Image.open(path)\n",
    "\n",
    "        # Resize and convert to tensor\n",
    "        transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize(CFG.image_size),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ])\n",
    "        image = transform(image)\n",
    "        \n",
    "        # Rescale image\n",
    "        image = image.float()\n",
    "        image /= 255.0\n",
    "        \n",
    "        # Insert decoded image and return\n",
    "        inp[\"images\"] = image\n",
    "        return inp\n",
    "\n",
    "    def decode_label(label, num_classes):\n",
    "        label = torch.tensor(label).float()\n",
    "        label = label.view(num_classes)\n",
    "        return label\n",
    "\n",
    "    def decode_with_labels(inp, labels):\n",
    "        inp = decode_image(inp)\n",
    "        label = decode_label(labels[0], CFG.num_classes)\n",
    "        aux_label = decode_label(labels[1], CFG.num_aux_classes)\n",
    "        return (inp, (label, aux_label))\n",
    "\n",
    "    return decode_with_labels if with_labels else decode_image\n",
    "\n",
    "class INetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths, features, labels=None, aux_labels=None, decode_fn=None, augment_fn=None):\n",
    "        self.paths = paths\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.aux_labels = aux_labels\n",
    "        self.decode_fn = decode_fn\n",
    "        self.augment_fn = augment_fn\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp = {\"images\": self.paths[idx], \"features\": self.features[idx]}\n",
    "        if self.labels is not None:\n",
    "            slices = self.decode_fn(inp, (self.labels[idx], self.aux_labels[idx]))\n",
    "            if self.augment_fn is not None:\n",
    "                slices = self.augment_fn(inp, (self.labels[idx], self.aux_labels[idx]))\n",
    "        else:\n",
    "            slices = self.decode_fn(inp)\n",
    "            if self.augment_fn is not None:\n",
    "                slices = self.augment_fn(inp)\n",
    "\n",
    "        return slices\n",
    "\n",
    "def build_dataset(\n",
    "    paths,\n",
    "    features,\n",
    "    labels=None,\n",
    "    aux_labels=None,\n",
    "    batch_size=32,\n",
    "    augment=False,\n",
    "    shuffle=False,\n",
    "):\n",
    "    decode_fn = build_decoder(labels is not None or aux_labels is not None)\n",
    "    augment_fn = build_augmenter() if augment else None\n",
    "    dataset = INetDataset(paths, features, labels, aux_labels, decode_fn, augment_fn)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=CFG.num_folds, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "# Create separate bin for each traits\n",
    "for i, trait in enumerate(CFG.class_names):\n",
    "\n",
    "    # Determine the bin edges dynamically based on the distribution of traits\n",
    "    bin_edges = np.percentile(df[trait], np.linspace(0, 100, CFG.num_folds + 1))\n",
    "    df[f\"bin_{i}\"] = np.digitize(df[trait], bin_edges)\n",
    "\n",
    "# Concatenate the bins into a final bin\n",
    "df[\"final_bin\"] = (\n",
    "    df[[f\"bin_{i}\" for i in range(len(CFG.class_names))]]\n",
    "    .astype(str)\n",
    "    .agg(\"\".join, axis=1)\n",
    ")\n",
    "\n",
    "# Perform the stratified split using final bin\n",
    "df = df.reset_index(drop=True)\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(df, df[\"final_bin\"])):\n",
    "    df.loc[valid_idx, \"fold\"] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from full data\n",
    "sample_df = df.copy()\n",
    "train_df = sample_df[sample_df.fold != CFG.fold]\n",
    "valid_df = sample_df[sample_df.fold == CFG.fold]\n",
    "print(f\"# Num Train: {len(train_df)} | Num Valid: {len(valid_df)}\")\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_df[CFG.feature_names].values)\n",
    "valid_features = scaler.transform(valid_df[CFG.feature_names].values)\n",
    "\n",
    "# Train\n",
    "train_paths = train_df.image_path.values\n",
    "train_labels = train_df[CFG.class_names].values\n",
    "train_aux_labels = train_df[CFG.aux_class_names].values\n",
    "train_ds = build_dataset(train_paths, train_features, train_labels, train_aux_labels,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=True, augment=True)\n",
    "\n",
    "# Valid\n",
    "valid_paths = valid_df.image_path.values\n",
    "valid_labels = valid_df[CFG.class_names].values\n",
    "valid_aux_labels = valid_df[CFG.aux_class_names].values\n",
    "valid_ds = build_dataset(valid_paths, valid_features, valid_labels, valid_aux_labels,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=False, augment=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample of the data\n",
    "inps, tars = next(iter(train_ds))\n",
    "imgs = inps[\"images\"]\n",
    "\n",
    "# Plot the first eight images of the sample with their labels\n",
    "num_imgs, num_cols = 8, 4\n",
    "plt.figure(figsize=(4 * num_cols, num_imgs // num_cols * 5))\n",
    "for i, (img, tar) in enumerate(zip(imgs[:num_imgs], tars[0][:num_imgs])):\n",
    "    plt.subplot(num_imgs // num_cols, num_cols, i + 1)\n",
    "\n",
    "    img = img.permute(1, 2, 0)  # Change (C, H, W) to (H, W, C)\n",
    "    \n",
    "    img = img.numpy()\n",
    "    tar = tar.numpy()\n",
    "    \n",
    "    img = (img - img.min()) / (img.max() + 1e-4)\n",
    "\n",
    "    formatted_tar = \"\\n\".join(\n",
    "        [\n",
    "            \", \".join(\n",
    "                f\"{name.replace('_mean','')}: {val:.2f}\"\n",
    "                for name, val in zip(CFG.class_names[j : j + 3], tar[j : j + 3])\n",
    "            )\n",
    "            for j in range(0, len(CFG.class_names), 3)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"[{formatted_tar}]\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Define loss</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.y_median = torch.tensor(train_df[CFG.class_names].median(axis=0).values).to(device)\n",
    "CFG.eps = torch.tensor([1e-6]).to(device)\n",
    "\n",
    "class R2Loss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        ss_res = (y_true - y_pred)**2\n",
    "        ss_total = (y_true - CFG.y_median)**2\n",
    "        loss = torch.sum(ss_res, dim=0) / torch.maximum(torch.sum(ss_total, dim=0), CFG.eps)\n",
    "        return torch.mean(loss)\n",
    "\n",
    "class R2Metric(torchmetrics.Metric):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add_state(\"loss\", default=torch.tensor(0.), dist_reduce_fx=\"mean\")\n",
    "\n",
    "    def update(self, y_true, y_pred):\n",
    "        ss_res = torch.sum((y_true - y_pred) ** 2, dim=0)\n",
    "        ss_total = torch.sum((y_true - CFG.y_median) ** 2, dim=0)\n",
    "        loss = torch.sum(ss_res, dim=0) / torch.maximum(torch.sum(ss_total, dim=0), CFG.eps)\n",
    "        self.loss.add_(loss.mean())\n",
    "\n",
    "    def compute(self):\n",
    "        return self.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Construct model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_timm_model(query):\n",
    "    search_result = [n for n in timm.list_models(pretrained=True) if query in n]\n",
    "    for i, name in enumerate(search_result):\n",
    "        print(f'{i:02d} | {name}')\n",
    "        \n",
    "# search_timm_model('efficientnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class INet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(INet, self).__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "                'efficientnet_b2',\n",
    "                pretrained=True,\n",
    "                num_classes=0,\n",
    "            )\n",
    "        self.dropout1 = torch.nn.Dropout(0.2)\n",
    "        self.fc1 = torch.nn.Linear(CFG.inet_output_size, CFG.num_classes)\n",
    "\n",
    "        self.dense = torch.nn.Sequential(\n",
    "            torch.nn.Linear(CFG.num_features, 326),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Linear(326, 64),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Dropout(0.1),\n",
    "            torch.nn.Linear(64, CFG.num_aux_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, images, features):\n",
    "        x1 = self.backbone(images)\n",
    "        x1 = self.dropout1(x1)\n",
    "        x1 = self.fc1(x1)\n",
    "\n",
    "        features = features.to(torch.float32)\n",
    "        x2 = self.dense(features)\n",
    "\n",
    "        return {\"head\": x1, \"aux_head\": x2}\n",
    "\n",
    "model = INet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>LR Scheduler</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_scheduler(optimizer):\n",
    "    lr_start, lr_max, lr_min = 5e-5, 8e-6 * CFG.batch_size, 1e-5\n",
    "    lr_ramp_ep, lr_sus_ep, lr_decay = 3, 0, 0.75\n",
    "\n",
    "    def lrfn(epoch):  # Learning rate update function\n",
    "        if epoch < lr_ramp_ep: \n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep: \n",
    "            lr = lr_max\n",
    "        elif CFG.lr_mode == 'exp': \n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        elif CFG.lr_mode == 'step': \n",
    "            lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n",
    "        elif CFG.lr_mode == 'cos':\n",
    "            decay_total_epochs = CFG.epochs - lr_ramp_ep - lr_sus_ep + 3\n",
    "            decay_epoch_index = epoch - lr_ramp_ep - lr_sus_ep\n",
    "            phase = math.pi * decay_epoch_index / decay_total_epochs\n",
    "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n",
    "        return lr\n",
    "\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lrfn)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = get_lr_scheduler(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_ds, optimizer, loss_fn_head, loss_fn_aux_head, device):\n",
    "    model.train()\n",
    "    for inp, (labels, aux_labels) in tqdm(train_ds):\n",
    "        optimizer.zero_grad()\n",
    "        labels = labels.to(device)\n",
    "        aux_labels = aux_labels.to(device)\n",
    "        images = inp[\"images\"].to(device)\n",
    "        features = inp[\"features\"].to(device)\n",
    "\n",
    "        outputs = model(images, features)\n",
    "        loss_head = loss_fn_head(outputs[\"head\"], labels)\n",
    "        loss_aux_head = loss_fn_aux_head(outputs[\"aux_head\"], aux_labels)\n",
    "        loss = loss_head\n",
    "        loss += 0.3 * loss_aux_head\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Initialize best R2 and best epoch\n",
    "best_R2 = -np.inf\n",
    "best_epoch = -1\n",
    "\n",
    "# Initialize loss functions\n",
    "loss_fn_head = R2Loss().to(device)\n",
    "loss_fn_aux_head = R2Loss().to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(CFG.epochs):\n",
    "    print(f\"Epoch: {epoch+1} | LR: {optimizer.param_groups[0]['lr']:0.10f}\")\n",
    "\n",
    "    try:\n",
    "        if CFG.profile:\n",
    "            with torch.profiler.profile(activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "                with torch.profiler.record_function(\"model_inference\"):\n",
    "                        train_epoch(model, train_ds, optimizer, loss_fn_head, loss_fn_aux_head, device)\n",
    "        else:\n",
    "            train_epoch(model, train_ds, optimizer, loss_fn_head, loss_fn_aux_head, device)\n",
    "    except RuntimeError as e:\n",
    "        if str(e).startswith(\"mat1 and mat2 shapes cannot be multiplied\"):\n",
    "            raise ValueError(f\"Wrong output size for the imagenet in config (CFG.inet_output_size): should be {str(e).split('x')[1].split(' ')[0]} but is {CFG.inet_output_size}.\")\n",
    "        else:\n",
    "            raise RuntimeError(e)\n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Calculate R2 score on validation set\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        outputs = [model(inp[\"images\"].to(device), inp[\"features\"].to(device)) for inp, _ in tqdm(valid_ds)]\n",
    "        preds = torch.cat([o[\"head\"] for o in outputs])\n",
    "        labels = torch.cat([labels[1] for _, labels in valid_ds])\n",
    "        R2 = R2Metric().to(device)\n",
    "        R2 = R2(preds.to(device), labels.to(device))\n",
    "\n",
    "    # Update best R2 and best epoch\n",
    "    if R2 > best_R2:\n",
    "        best_R2 = R2\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "    print(f\"R2: {R2:.4f} | Best R2: {best_R2:.4f} (epoch {best_epoch+1})\")\n",
    "\n",
    "\n",
    "# Print profiler results\n",
    "if CFG.profile:\n",
    "    print(prof.key_averages().table(sort_by=\"cuda_time_total\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Result\n",
    "print(\"#\" * 10 + \" Result \" + \"#\" * 10)\n",
    "print(f\"Best R2: {best_R2:.5f}\")\n",
    "print(f\"Best Epoch: {best_epoch}\")\n",
    "print(\"#\" * 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test_paths = test_df.image_path.values\n",
    "test_features = scaler.transform(test_df[CFG.feature_names].values)\n",
    "test_ds = build_dataset(test_paths, test_features, batch_size=CFG.batch_size,\n",
    "                        shuffle=False, augment=False)\n",
    "\n",
    "preds = []\n",
    "for inp in tqdm(test_ds):\n",
    "    with torch.no_grad():\n",
    "        batch_preds = model(inp[\"images\"].to(device), inp[\"features\"].to(device))[\"head\"]\n",
    "        preds.append(batch_preds)\n",
    "\n",
    "# Concatenate all predictions\n",
    "preds = torch.cat(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = test_df[[\"id\"]].copy()\n",
    "target_cols = [x.replace(\"_mean\",\"\") for x in CFG.class_names]\n",
    "pred_df[target_cols] = preds.tolist()\n",
    "\n",
    "pred_df.to_csv(\"submission.csv\", index=False)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
